{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4568ba-dcdc-4d27-a43c-fd56723424c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sha2n\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp313-cp313-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.9 MB 468.3 kB/s eta 0:00:29\n",
      "   - -------------------------------------- 0.5/13.9 MB 468.3 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 0.8/13.9 MB 503.1 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.8/13.9 MB 503.1 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.8/13.9 MB 503.1 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 1.0/13.9 MB 511.6 kB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 1.8/13.9 MB 811.1 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 1.8/13.9 MB 811.1 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.1/13.9 MB 845.4 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 2.6/13.9 MB 915.8 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.1/13.9 MB 1.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 3.4/13.9 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 3.7/13.9 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 3.9/13.9 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 4.5/13.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 4.7/13.9 MB 1.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.2/13.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 5.8/13.9 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.0/13.9 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.6/13.9 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.1/13.9 MB 1.4 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 7.3/13.9 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 7.9/13.9 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.4/13.9 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 8.9/13.9 MB 1.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.2/13.9 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.7/13.9 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.5/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.5/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.7/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.3/13.9 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.8/13.9 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.1/13.9 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.6/13.9 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.4/13.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 1.7 MB/s  0:00:08\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl (115 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/630.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 630.6/630.6 kB 2.5 MB/s  0:00:00\n",
      "Downloading thinc-8.3.6-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.0 MB/s  0:00:01\n",
      "Downloading blis-1.3.0-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 553.1 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 0.8/6.3 MB 857.4 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.0/6.3 MB 1.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.3/6.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.1/6.3 MB 1.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 2.4/6.3 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.4/6.3 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.1/6.3 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.9/6.3 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.2/6.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.0/6.3 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.3 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 1.6 MB/s  0:00:04\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.4 MB 2.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/5.4 MB 2.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/5.4 MB 2.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.4 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.8/5.4 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.4 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.9/5.4 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.1/5.4 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.1/5.4 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.7/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.2/5.4 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 1.7 MB/s  0:00:03\n",
      "Downloading marisa_trie-1.3.1-cp313-cp313-win_amd64.whl (139 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "\n",
      "   -- -------------------------------------  1/18 [wasabi]\n",
      "   -- -------------------------------------  1/18 [wasabi]\n",
      "   -- -------------------------------------  1/18 [wasabi]\n",
      "   ---- -----------------------------------  2/18 [spacy-loggers]\n",
      "   ---- -----------------------------------  2/18 [spacy-loggers]\n",
      "   ---- -----------------------------------  2/18 [spacy-loggers]\n",
      "   ------ ---------------------------------  3/18 [spacy-legacy]\n",
      "   ------ ---------------------------------  3/18 [spacy-legacy]\n",
      "   ------ ---------------------------------  3/18 [spacy-legacy]\n",
      "   ------ ---------------------------------  3/18 [spacy-legacy]\n",
      "   -------- -------------------------------  4/18 [smart-open]\n",
      "   -------- -------------------------------  4/18 [smart-open]\n",
      "   -------- -------------------------------  4/18 [smart-open]\n",
      "   -------- -------------------------------  4/18 [smart-open]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   ----------------- ----------------------  8/18 [catalogue]\n",
      "   -------------------- -------------------  9/18 [blis]\n",
      "   -------------------- -------------------  9/18 [blis]\n",
      "   -------------------- -------------------  9/18 [blis]\n",
      "   -------------------- -------------------  9/18 [blis]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ------------------------ --------------- 11/18 [preshed]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   ---------------------------- ----------- 13/18 [langcodes]\n",
      "   ---------------------------- ----------- 13/18 [langcodes]\n",
      "   ---------------------------- ----------- 13/18 [langcodes]\n",
      "   ------------------------------- -------- 14/18 [confection]\n",
      "   ------------------------------- -------- 14/18 [confection]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ---------------------------------------- 18/18 [spacy]\n",
      "\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 murmurhash-1.0.13 preshed-3.0.10 smart-open-7.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adaea2f0-63f2-4ac3-a6de-695f2187a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 2.9/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.2 MB/s  0:00:04\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\sha2n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06cdfc3e-755c-479e-8baa-5d7c7780830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# load english language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# example text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "#Process text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f201c7b4-eed0-47b3-8a02-c55f8cd79485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K. startup for $1 billion."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3270e684-3a40-45bb-aa1a-5c16a30be60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities, Phrases, and Concepts: \n",
      "Apple          ORG                0         5\n",
      "U.K.           GPE               27        31\n",
      "$1 billion     MONEY             44        54\n"
     ]
    }
   ],
   "source": [
    "# print named entities found in the text.\n",
    "print(\"Named Entities, Phrases, and Concepts: \")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:15}{ent.label_:10}{ent.start_char:10}{ent.end_char:10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b67e16-f043-4973-836c-4dafa57716a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"data science and ai gen ai has greate career ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67059a3f-2643-4694-a35e-7d023d9f3611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data science and ai gen ai has greate career ahead"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e7aa67-b334-4646-aeb0-6b50a07da386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "science\n",
      "and\n",
      "ai\n",
      "gen\n",
      "ai\n",
      "has\n",
      "greate\n",
      "career\n",
      "ahead\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9cdd37-d059-410e-b703-2a6da6bed2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "NOUN\n",
      "CCONJ\n",
      "AUX\n",
      "PROPN\n",
      "PROPN\n",
      "AUX\n",
      "ADJ\n",
      "NOUN\n",
      "ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fb4c0c8-4c54-4fc0-8f6e-d8b3239ae617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN\n",
      "science : NOUN\n",
      "and : CCONJ\n",
      "ai : AUX\n",
      "gen : PROPN\n",
      "ai : PROPN\n",
      "has : AUX\n",
      "greate : ADJ\n",
      "career : NOUN\n",
      "ahead : ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,':', token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc9b4214-4b7c-4539-af00-ccada08269de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN --> data compound\n",
      "science : NOUN --> science nsubj\n",
      "and : CCONJ --> and cc\n",
      "ai : AUX --> ai aux\n",
      "gen : PROPN --> gen compound\n",
      "ai : PROPN --> ai conj\n",
      "has : AUX --> have aux\n",
      "greate : ADJ --> greate ROOT\n",
      "career : NOUN --> career dobj\n",
      "ahead : ADV --> ahead advmod\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,':', token.pos_,'-->', token.lemma_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ffdf40-4cf0-4472-a328-1a832f33ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN --> data compound NN compound xxxx True False\n",
      "science : NOUN --> science nsubj NN nsubj xxxx True False\n",
      "and : CCONJ --> and cc CC cc xxx True True\n",
      "ai : AUX --> ai aux NNP aux xx True False\n",
      "gen : PROPN --> gen compound NNP compound xxx True False\n",
      "ai : PROPN --> ai conj NNP conj xx True False\n",
      "has : AUX --> have aux VBZ aux xxx True True\n",
      "greate : ADJ --> greate ROOT JJ ROOT xxxx True False\n",
      "career : NOUN --> career dobj NN dobj xxxx True False\n",
      "ahead : ADV --> ahead advmod RB advmod xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,':', token.pos_,'-->', token.lemma_, token.dep_, token.tag_, token.dep_,\n",
    "         token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a09dd496-945c-457a-bfba-85c9ee8de595",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "395339a8-2f3c-4504-ad65-da9dfb431e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ede4c4fc-6d6c-4a6b-a090-19b027b5c4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doing',\n",
       " 'he',\n",
       " 'per',\n",
       " 'seems',\n",
       " 'although',\n",
       " 'since',\n",
       " 'her',\n",
       " 'sometime',\n",
       " 'anything',\n",
       " 'by',\n",
       " 'front',\n",
       " 'besides',\n",
       " 'in',\n",
       " 'do',\n",
       " 'everyone',\n",
       " 'might',\n",
       " 'yourself',\n",
       " 'anyway',\n",
       " 'around',\n",
       " 'regarding',\n",
       " 'eight',\n",
       " 'namely',\n",
       " '’s',\n",
       " 'really',\n",
       " 'six',\n",
       " 'unless',\n",
       " 'amount',\n",
       " 'due',\n",
       " 'is',\n",
       " 'perhaps',\n",
       " 'ourselves',\n",
       " 'see',\n",
       " 'becoming',\n",
       " 'whom',\n",
       " 'until',\n",
       " 'as',\n",
       " 'name',\n",
       " 'anywhere',\n",
       " 'after',\n",
       " 'you',\n",
       " 'get',\n",
       " 'his',\n",
       " 'the',\n",
       " 'when',\n",
       " 'seemed',\n",
       " 'could',\n",
       " 'how',\n",
       " 'third',\n",
       " 'nobody',\n",
       " \"'m\",\n",
       " 'but',\n",
       " 'well',\n",
       " 'bottom',\n",
       " 'had',\n",
       " 'can',\n",
       " 'became',\n",
       " 'rather',\n",
       " 'would',\n",
       " 'itself',\n",
       " 'few',\n",
       " 'already',\n",
       " 'nowhere',\n",
       " 'without',\n",
       " 'next',\n",
       " 'made',\n",
       " 'mine',\n",
       " 'anyone',\n",
       " 'one',\n",
       " 'did',\n",
       " '‘ll',\n",
       " 'neither',\n",
       " 'own',\n",
       " 'hereupon',\n",
       " 'except',\n",
       " 'throughout',\n",
       " 'forty',\n",
       " 'each',\n",
       " 'n’t',\n",
       " 'that',\n",
       " 'both',\n",
       " '’re',\n",
       " 'please',\n",
       " 'why',\n",
       " 'should',\n",
       " 'of',\n",
       " 'been',\n",
       " 'for',\n",
       " 'always',\n",
       " 'seem',\n",
       " 'at',\n",
       " \"n't\",\n",
       " 'else',\n",
       " 'to',\n",
       " 'among',\n",
       " 'during',\n",
       " 'there',\n",
       " \"'ll\",\n",
       " 'whatever',\n",
       " 'other',\n",
       " 'somehow',\n",
       " 'which',\n",
       " 'twelve',\n",
       " 'whence',\n",
       " 'whither',\n",
       " 'still',\n",
       " 'him',\n",
       " 'themselves',\n",
       " 'thence',\n",
       " 'because',\n",
       " 'together',\n",
       " '’ve',\n",
       " 'call',\n",
       " 'thereafter',\n",
       " 'moreover',\n",
       " 'two',\n",
       " 'thereby',\n",
       " 'hers',\n",
       " 'than',\n",
       " 'such',\n",
       " 'whole',\n",
       " 'twenty',\n",
       " 'yours',\n",
       " 'if',\n",
       " 'becomes',\n",
       " 'fifteen',\n",
       " 'otherwise',\n",
       " 'afterwards',\n",
       " 'further',\n",
       " 'almost',\n",
       " 'and',\n",
       " 'whereas',\n",
       " 'a',\n",
       " 'yourselves',\n",
       " 'hereafter',\n",
       " 'along',\n",
       " 'herself',\n",
       " 'ten',\n",
       " '‘d',\n",
       " 'least',\n",
       " 'ever',\n",
       " 'does',\n",
       " 'last',\n",
       " 'put',\n",
       " 'enough',\n",
       " 'us',\n",
       " 'mostly',\n",
       " 'myself',\n",
       " 'thru',\n",
       " 'wherein',\n",
       " 'much',\n",
       " 'those',\n",
       " 'anyhow',\n",
       " 'former',\n",
       " 'whereafter',\n",
       " 'towards',\n",
       " 'once',\n",
       " 'while',\n",
       " 'must',\n",
       " 'across',\n",
       " 'beside',\n",
       " 'on',\n",
       " 'most',\n",
       " 'too',\n",
       " 'them',\n",
       " 'whose',\n",
       " \"'ve\",\n",
       " \"'d\",\n",
       " 'so',\n",
       " 'everywhere',\n",
       " 'about',\n",
       " 'me',\n",
       " 'she',\n",
       " 'our',\n",
       " 'hereby',\n",
       " 'then',\n",
       " 'move',\n",
       " 'ca',\n",
       " 'noone',\n",
       " 'against',\n",
       " 'empty',\n",
       " 'am',\n",
       " 'others',\n",
       " 'or',\n",
       " 'become',\n",
       " 'beforehand',\n",
       " 'being',\n",
       " 'alone',\n",
       " 'beyond',\n",
       " 'hundred',\n",
       " 'fifty',\n",
       " 'will',\n",
       " \"'s\",\n",
       " 'this',\n",
       " 'any',\n",
       " 'what',\n",
       " 'sixty',\n",
       " 'n‘t',\n",
       " 'say',\n",
       " 'amongst',\n",
       " 'not',\n",
       " 'somewhere',\n",
       " 'over',\n",
       " 'often',\n",
       " 'was',\n",
       " 'cannot',\n",
       " 'even',\n",
       " 'are',\n",
       " 'ours',\n",
       " '’d',\n",
       " 'everything',\n",
       " 'down',\n",
       " 'has',\n",
       " 'it',\n",
       " '‘s',\n",
       " 'below',\n",
       " 'take',\n",
       " 'up',\n",
       " 'using',\n",
       " 'onto',\n",
       " 'five',\n",
       " 'i',\n",
       " 'their',\n",
       " 'therein',\n",
       " 'quite',\n",
       " 'we',\n",
       " 'top',\n",
       " 'used',\n",
       " 'may',\n",
       " 'however',\n",
       " 'wherever',\n",
       " 'very',\n",
       " 'nothing',\n",
       " 'toward',\n",
       " '‘ve',\n",
       " 'just',\n",
       " 'side',\n",
       " 'its',\n",
       " 'more',\n",
       " 'your',\n",
       " 'full',\n",
       " 'none',\n",
       " 'upon',\n",
       " 'another',\n",
       " 'my',\n",
       " 'therefore',\n",
       " 'less',\n",
       " 'between',\n",
       " 'who',\n",
       " 'various',\n",
       " 'go',\n",
       " 'either',\n",
       " 'whenever',\n",
       " 'behind',\n",
       " 'formerly',\n",
       " 'these',\n",
       " 'an',\n",
       " 'they',\n",
       " 'yet',\n",
       " 'whoever',\n",
       " 'nor',\n",
       " 're',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'latterly',\n",
       " 'thereupon',\n",
       " 'where',\n",
       " 'only',\n",
       " 'again',\n",
       " 'be',\n",
       " 'same',\n",
       " 'whereupon',\n",
       " 'from',\n",
       " 'give',\n",
       " 'serious',\n",
       " 'done',\n",
       " 'nevertheless',\n",
       " '‘m',\n",
       " 'have',\n",
       " 'out',\n",
       " 'hence',\n",
       " 'elsewhere',\n",
       " 'though',\n",
       " '’ll',\n",
       " 'three',\n",
       " 'here',\n",
       " 'through',\n",
       " 'whereby',\n",
       " '‘re',\n",
       " 'within',\n",
       " 'were',\n",
       " 'no',\n",
       " 'herein',\n",
       " 'with',\n",
       " 'four',\n",
       " 'sometimes',\n",
       " 'every',\n",
       " 'also',\n",
       " 'whether',\n",
       " 'above',\n",
       " '’m',\n",
       " 'via',\n",
       " 'someone',\n",
       " 'off',\n",
       " 'into',\n",
       " 'make',\n",
       " 'all',\n",
       " \"'re\",\n",
       " 'now',\n",
       " 'meanwhile',\n",
       " 'some',\n",
       " 'nine',\n",
       " 'keep',\n",
       " 'many',\n",
       " 'back',\n",
       " 'show',\n",
       " 'seeming',\n",
       " 'several',\n",
       " 'eleven',\n",
       " 'thus',\n",
       " 'under',\n",
       " 'part',\n",
       " 'latter',\n",
       " 'never',\n",
       " 'indeed',\n",
       " 'first',\n",
       " 'something']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d8cb2e2-d890-4926-bc51-4e8c284fbfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38594fc9-3e2e-4881-ae84-7111cd83364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea475053-539f-4925-8630-b73c8acf2768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "380dd496-2ff6-4193-957e-bfbe92f3db82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc =nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5191855-30df-4047-9c74-1defeeba44df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25acfeab-3169-4101-af3c-e9993287f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e77ed10-c0b2-4793-889e-e97ea7cd4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to calculate the frequency of each and every token, how many time token repeated in text\n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcf0f80f-de2a-47d2-aba2-a10106213da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ed778ff-03f8-4d95-b4e0-53e57fb361bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c08af1c-202e-402a-888e-b4c7239d9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word]= word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0379a865-6a10-4ca9-9fa8-cff284e06e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 0.09090909090909091,\n",
       " 'types': 0.09090909090909091,\n",
       " 'extractive': 0.09090909090909091,\n",
       " 'summarization': 1.0,\n",
       " 'tasks': 0.09090909090909091,\n",
       " 'depending': 0.18181818181818182,\n",
       " 'program': 0.09090909090909091,\n",
       " 'focuses': 0.18181818181818182,\n",
       " 'generic': 0.2727272727272727,\n",
       " 'obtaining': 0.09090909090909091,\n",
       " 'summary': 0.36363636363636365,\n",
       " 'abstract': 0.18181818181818182,\n",
       " 'collection': 0.2727272727272727,\n",
       " 'documents': 0.18181818181818182,\n",
       " 'sets': 0.09090909090909091,\n",
       " 'images': 0.2727272727272727,\n",
       " 'videos': 0.2727272727272727,\n",
       " 'news': 0.36363636363636365,\n",
       " 'stories': 0.09090909090909091,\n",
       " 'etc': 0.09090909090909091,\n",
       " 'second': 0.09090909090909091,\n",
       " 'query': 0.36363636363636365,\n",
       " 'relevant': 0.18181818181818182,\n",
       " 'called': 0.18181818181818182,\n",
       " 'based': 0.09090909090909091,\n",
       " 'summarizes': 0.09090909090909091,\n",
       " 'objects': 0.09090909090909091,\n",
       " 'specific': 0.09090909090909091,\n",
       " 'Summarization': 0.09090909090909091,\n",
       " 'systems': 0.09090909090909091,\n",
       " 'able': 0.09090909090909091,\n",
       " 'create': 0.09090909090909091,\n",
       " 'text': 0.09090909090909091,\n",
       " 'summaries': 0.18181818181818182,\n",
       " 'machine': 0.09090909090909091,\n",
       " 'generated': 0.09090909090909091,\n",
       " 'user': 0.09090909090909091,\n",
       " 'needs': 0.09090909090909091,\n",
       " '\\n': 0.18181818181818182,\n",
       " 'example': 0.2727272727272727,\n",
       " 'problem': 0.18181818181818182,\n",
       " 'document': 0.36363636363636365,\n",
       " 'attempts': 0.09090909090909091,\n",
       " 'automatically': 0.2727272727272727,\n",
       " 'produce': 0.09090909090909091,\n",
       " 'given': 0.18181818181818182,\n",
       " 'interested': 0.09090909090909091,\n",
       " 'generating': 0.09090909090909091,\n",
       " 'single': 0.09090909090909091,\n",
       " 'source': 0.18181818181818182,\n",
       " 'use': 0.09090909090909091,\n",
       " 'multiple': 0.09090909090909091,\n",
       " 'cluster': 0.09090909090909091,\n",
       " 'articles': 0.2727272727272727,\n",
       " 'topic': 0.18181818181818182,\n",
       " 'multi': 0.09090909090909091,\n",
       " 'related': 0.18181818181818182,\n",
       " 'application': 0.18181818181818182,\n",
       " 'summarizing': 0.09090909090909091,\n",
       " 'Imagine': 0.09090909090909091,\n",
       " 'system': 0.2727272727272727,\n",
       " 'pulls': 0.09090909090909091,\n",
       " 'web': 0.09090909090909091,\n",
       " 'concisely': 0.09090909090909091,\n",
       " 'represents': 0.09090909090909091,\n",
       " 'latest': 0.09090909090909091,\n",
       " 'Image': 0.09090909090909091,\n",
       " 'automatic': 0.09090909090909091,\n",
       " 'consists': 0.09090909090909091,\n",
       " 'selecting': 0.09090909090909091,\n",
       " 'representative': 0.18181818181818182,\n",
       " 'set': 0.18181818181818182,\n",
       " 'larger': 0.09090909090909091,\n",
       " 'images.[4': 0.09090909090909091,\n",
       " 'context': 0.09090909090909091,\n",
       " 'useful': 0.09090909090909091,\n",
       " 'results': 0.09090909090909091,\n",
       " 'image': 0.09090909090909091,\n",
       " 'exploration': 0.09090909090909091,\n",
       " 'Video': 0.09090909090909091,\n",
       " 'domain': 0.09090909090909091,\n",
       " 'creates': 0.09090909090909091,\n",
       " 'trailer': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'video': 0.09090909090909091,\n",
       " 'applications': 0.09090909090909091,\n",
       " 'consumer': 0.09090909090909091,\n",
       " 'personal': 0.09090909090909091,\n",
       " 'want': 0.18181818181818182,\n",
       " 'skip': 0.09090909090909091,\n",
       " 'boring': 0.18181818181818182,\n",
       " 'repetitive': 0.09090909090909091,\n",
       " 'actions': 0.09090909090909091,\n",
       " 'Similarly': 0.09090909090909091,\n",
       " 'surveillance': 0.09090909090909091,\n",
       " 'extract': 0.09090909090909091,\n",
       " 'important': 0.09090909090909091,\n",
       " 'suspicious': 0.09090909090909091,\n",
       " 'activity': 0.09090909090909091,\n",
       " 'ignoring': 0.09090909090909091,\n",
       " 'redundant': 0.09090909090909091,\n",
       " 'frames': 0.09090909090909091,\n",
       " 'captured': 0.09090909090909091}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd2a44-dc35-41fc-aa40-998de92f04b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20043d9c-c84b-41b0-8c4a-b4522835bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_token = [sent for sent in doc.sents]\n",
    "sentence_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fef6092a-7f09-468b-b04c-96285b579116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_score = {}\n",
    "for sent in sentence_token:\n",
    "    for word in sent:\n",
    "        if word.text.lower()in word_frequencies.keys():\n",
    "            if sent not in sentence_score.keys():\n",
    "                sentence_score[sent]=word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_score[sent]+=word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66edd0d2-8f98-4ef0-8965-4608af3d7ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8303ecc-5b9e-47dc-bb2b-484484ad2f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df688632-029c-463f-ad65-14372233b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4edfaf6d-658e-45f1-ad95-44d7f898e6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_lenght = int(len(sentence_token)*0.4)\n",
    "select_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bece1459-8b63-49fa-8662-dd7e60717c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = nlargest(select_lenght, sentence_score, key = sentence_score.get )\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea41c73d-8860-4da4-b457-f04dcdd24c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
       " 'Image collection summarization is another application example of automatic summarization.',\n",
       " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary = [word.text for word in summary]\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d4694-38dc-4fc9-925e-51e9b6d78c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731ca8c-7e76-49c4-a3c2-9429f53d24af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef18e5-ba13-4ddb-8eee-b6fa7a362731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
